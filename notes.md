## Author list

* Damien Irving (Melbourne 2015 poster session coordinator, lead author)  
* Kim Doyle (Melbourne 2016 poster session coordinator)  
* Tim Rice (Melbourne 2017 poster session coordinator)  
* Stephanie Bradbury (Brisbane 2016 poster session coordinator)  
* Amanda Miotto (Brisbane 2017 poster session coordinator)  
* Heidi Perrett (Brisbane 2017 poster session coordinator)  
* Belinda Weaver (ResBaz Brisbane coordinator)  
* David Flanders (ResBaz Melbourne coordinator)  

## Introduction

It would be of assistance to educators, open science thinkers/advocates and individual researchers to lift the veil
and understand what tools people are using to do their work. 
This information isn't covered in journal papers 
and even within research departments/groups people can be ashamed to talk about the tools they use.

Relevant literature:  
* Around 18% of all researchers use LaTeX [(Pepe, 2016)](https://www.authorea.com/users/3/articles/107393-how-many-scholarly-articles-are-written-in-latex/_show_article)  


## Methodology

The ResBaz poster sessions are explained at [this post](http://melbourne.resbaz.edu.au/post/108054124634/the-resbaz-poster-session-with-a-difference).

Research disciplines were taken from the [Australian and New Zealand Standard Research Classification (ANZSRC), 2008](http://www.abs.gov.au/ausstats/abs@.nsf/Products/6BB427AB9696C225CA2574180004463E?opendocument).

Scope of analysis:  
* Primary interest: Digital tools for collecting, organising, analysing and visualising/presenting data 
* Side interest: Digital tools that help with these data science tasks (e.g. referencing, document editing, graphics editing) 
* Out: Software that generates data (e.g. climate models, biological models, economic models)
* Out: Software for physical hardware (e.g. microscopes, scanners)
* Out: Online platforms for networking (e.g. twitter, LinkedIn, ResearchGate) or personal websites/blogging (e.g. wordpress, blogger)


## Results

### Demographics

- Number of posters
- Career breakdown
- Discipline breakdown

### Digital toolbox

#### Overall

- Programming languages
  - R, Python and MATLAB most popular, in that order
    - Libraries and IDE's of note...

- General data science tools
  - Excel, Prism most popular general purpose  
  - SPSS, Stata for statistics
  - ArcGIS for unstructured spatial data
  - Nvivo for qualitative data
  
  - Vast majority are pay, graphical tools
  
- Support tools
  - Community hasn't settled on favourite survey tool
  - Community hasn't settled on a favourite CAD tool
  - Sublime, Notepad++ and Vim most popular code editors
  - Version control: 
    - Git / GitHub most popular combination 
    - Comment on percentage of people who code who listed version control  
  - Document editing: 
    - Word most popular document editor.
    - LaTeX next (various editing platforms) 
    - Scrivener worth a mention
  - Endnote most popular reference manager. Mendeley and Papers next.
  - Graphics editing: Photoshop, GIMP, Illustrator, Inkscape
  - PowerPoint
  - Commmunity hasn't settled on favourite mind/concept mapping
  - Evernote popular for note taking
  - Dropbox and Google Drive most popular for file storage / sharing (low take-up of academic alternatives)
  

#### Discipline profiles

(For any that have at least 5 people)

| Discipline | Group | Common tools |
| :--- | :--- | :--- |
| biological sciences |  |  |
| | genetics / biochemistry and cell biology (23) | R & Python; Lots of open, command line discipline tools |
| | ecology (10) | R; Excel, ArcGIS; GIMP |
| | zoology (7) | R |
| medical and health sciences | | |
| | neurosciences (14) | MATLAB; Excel, SPSS;  |
| | public health and health services (6) | non-coders; Excel, SPSS, Stata |
| psychology and cognitive sciences | | |
| | psychology (10) | R, non-coders; Excel, SPSS |
| engineering (10) | | MATLAB |                               
| information and computing sciences (8) | | Javascript; Git |            
| studies in human society (7) | | non-coders |                      
| physical sciences | | |
| | astronomical and space sciences (6) | Python; Lots of open discipline tools; LaTeX |
| language, communication and culture (6) | | Python |           
| environmental sciences | | |
| | environmental science and management (6) | R, Python; Excel, ArcGIS |
| earth sciences | | |
| | atmospheric sciences / oceanography (6) | Python, Unix Shell; NCO; CDO; Git, LaTeX |
| economics (5) | | Spread. |                                    
| mathematical sciences (5) | | R; LaTeX |                        
| history and archaeology (4) | | non-coders |                      
| commerce, management, tourism and services (4) | | R, non-coders; NVivo, SPSS, AMOS |    
| built environment and design (3) | |  |                   
| agricultural and veterinary sciences (2) | | |           
| education (3) | | |                                      
| chemical sciences | | |                              
| studies in creative arts and writing | | |           
| law and legal studies  | | |                         
| philosophy and religious studies  | | |                
| technology | | |                                     


## Discussion / conclusions

There are so many tools that you couldn't possibly provide support and training for all of them.

What we can do with this dataset is identify the most popular tools (i.e. the ones to focus our training efforts on).
When teaching these tools, we need to recognise that researchers use a wide variety of tools
and that the specific tools they use will change over time.
If we can incorporate a strong emphasis on generic skills / best practices into our training,
people walk out with skills in that specific tool *and* 
generic skills that empower them to learn and use other tools more effectively.

The skills / best practices that cover all the tools on the posters can be broadly grouped as follows:
1. Discipline specific knowledge/skills (e.g. MRI analysis software)
2. Research statistics
3. Data visualisation best practices
4. Programming best practices
5. Spreadsheet best practices

Faculties offer (1) and (2) (the latter possibly in collaboration with Maths & Stats Department),
which leaves (3), (4) and (5) to departments like Research Platform Services.
We do programming best practices well (e.g. Software Carpentry),
spreadsheet best practices well (e.g. Data Carpentry),
but there seems to be a gap in what we offer for data visualisation best practices.

The usage patterns of the various digital research tools cross many discipline boundaries.
In other words, researchers from completely separate research fields can often have a lot in common
when it comes to the digital research tools that they use.

The plethora of closed and/or paid and/or no scripting tools is a barrier to open science that doesn't get much attention.

Open (and free) tools typically require coding skills (unlike paid/closed, which often have a GUI).
This means teaching coding best practices empowers researchers to do open science.

Further work: A more formal survey of the research community using the results from these open-ended posters 
as a starting point for designing the questions / format.
